{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratik doshi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import RegressorMixin\n",
    "from scipy import fftpack\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Relevant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The for a sample of sectoral indices have been taken. The sample is selected purely based on availability. Only those indices that have data for more than 2000 days (8 years) have been used. The list has been compiled in PB Analysis Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ['Nifty Auto',\n",
    " 'Nifty Bank',\n",
    " 'Nifty FMCG',\n",
    " 'Nifty Media',\n",
    " 'Nifty Midcap 50',\n",
    " 'Nifty',\n",
    " 'Nifty IT',\n",
    " 'Nifty Pharma',\n",
    " 'Nifty Realty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty Auto\n",
      "\n",
      "Nifty Bank\n",
      "\n",
      "Nifty FMCG\n",
      "\n",
      "Nifty Media\n",
      "\n",
      "Nifty Midcap 50\n",
      "\n",
      "Nifty\n",
      "\n",
      "Nifty IT\n",
      "\n",
      "Nifty Pharma\n",
      "\n",
      "Nifty Realty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '.\\\\Data\\\\'\n",
    "\n",
    "def load_df(folder):\n",
    "    return pd.read_csv(folder,usecols = [1,2,3,4],parse_dates = ['Date']).sort_values(by='Date').reset_index()\n",
    "\n",
    "refer = {}\n",
    "i = 0\n",
    "for file in sample:\n",
    "    print(file)\n",
    "    \n",
    "    refer[file] = load_df(base_dir + file + '.csv')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process will involve fitting a simple time series regression. Adding the seasonality component to the residuals of the regression and analysing the residuals that remain after adjusting for drift and seasonality. The P/B Analysis Notebook has already established that none of the indices have a stationary P/B ratio. The graphs of the indices however show little to no trend. The trend if exists will reflect in the time series regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty Auto ; Training Size: 3151 ; Testing Size: 351\n",
      "Nifty Bank ; Training Size: 4473 ; Testing Size: 497\n",
      "Nifty FMCG ; Training Size: 2074 ; Testing Size: 231\n",
      "Nifty Media ; Training Size: 3152 ; Testing Size: 351\n",
      "Nifty Midcap 50 ; Training Size: 2329 ; Testing Size: 259\n",
      "Nifty ; Training Size: 4473 ; Testing Size: 497\n",
      "Nifty IT ; Training Size: 4465 ; Testing Size: 497\n",
      "Nifty Pharma ; Training Size: 2074 ; Testing Size: 231\n",
      "Nifty Realty ; Training Size: 2982 ; Testing Size: 332\n"
     ]
    }
   ],
   "source": [
    "# Splitting training and testing data\n",
    "def split(X,test_size = 0.1):\n",
    "    classify = X.index < int(len(X)*(1-test_size))\n",
    "    \n",
    "    X_train = X[classify]\n",
    "    X_test = X[~classify]\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "test = {}\n",
    "train = {}\n",
    "for e in refer.keys():\n",
    "    train[e], test[e] = split(refer[e])\n",
    "    print(e,'; Training Size: ' + str(len(train[e])),'; Testing Size: ' + str(len(test[e])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building transformer to use the indices as the independent variable\n",
    "class IndexSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        indices = X.index\n",
    "        return np.array(indices.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63e1067686b45c1951e42ebcd7b94f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nift…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model(feature)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "#Modelling Drift\n",
    "drift = {}\n",
    "for index in train.keys():\n",
    "    drift[index] = Pipeline([('IndexSelector',IndexSelector()),\n",
    "                            ('Regressor',LinearRegression())])\n",
    "    drift[index].fit(train[index],train[index]['P/B'])\n",
    "\n",
    "def plot_model(feature):\n",
    "    print('R2 for testing data:',drift[feature].score(test[feature],test[feature]['P/B']))\n",
    "    predicted = drift[feature].predict(train[feature])\n",
    "    plt.figure(figsize = (10,15))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    plt.title(feature + ': Linear Regression')\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'], label = 'Actual P/B Ratio')\n",
    "    plt.plot(train[feature]['Date'],predicted,label = 'Predicted P/B Ratio')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(feature + ': Regression Residuals')\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'] - predicted, label ='Residuals')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(feature + ': Regression Performance on Test Data')\n",
    "    plt.plot(test[feature]['Date'],test[feature]['P/B'], label = 'P/B Ratio')\n",
    "    plt.plot(test[feature]['Date'],drift[feature].predict(test[feature]), label = 'Test Predictions')\n",
    "    plt.legend()\n",
    "#    plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + feature \n",
    "#              + '_LinearModel3.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "interact(plot_model, feature = train.keys())\n",
    "#for index in train.keys():\n",
    "#    plot_model(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 values on the testing data is very poor for linear regression. A custom regressor that simply returns the mean will be a better model than a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Mean Predicting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CustomRegressor\n",
    "class MeanRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.mean = np.median(y, axis = 0)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        pred[0:] = self.mean\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237dbaa5c7a242dcbda17fa8bb9f889c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nift…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model(feature)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Refitting drift model using meanregressor\n",
    "from ipywidgets import interact\n",
    "mean_drift = {}\n",
    "for index in train.keys():\n",
    "    mean_drift[index] = Pipeline([('IndexSelector',IndexSelector()),\n",
    "                            ('Regressor',MeanRegressor())])\n",
    "    mean_drift[index].fit(train[index],train[index]['P/B'])\n",
    "\n",
    "def plot_model(feature):\n",
    "    print('R2 for testing data:',mean_drift[feature].score(test[feature],test[feature]['P/B']))\n",
    "    predicted = mean_drift[feature].predict(train[feature])\n",
    "    plt.figure(figsize = (10,15))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    plt.title(feature + ': Naive Mean Model')\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'], label = 'Actual P/B Ratio')\n",
    "    plt.plot(train[feature]['Date'],predicted,label = 'Predicted P/B Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(feature + ': Mean Model Residuals')\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'] - predicted, label ='Residuals')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(feature + ': Performance of Predicting Mean on Test Data')\n",
    "    plt.plot(test[feature]['Date'],test[feature]['P/B'], label = 'P/B Ratio')\n",
    "    plt.plot(test[feature]['Date'],mean_drift[feature].predict(test[feature]), label = 'Test Predictions')\n",
    "    plt.legend()\n",
    "    \n",
    "#    plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + feature \n",
    "#              + '_MeanModel3.png')\n",
    "    \n",
    "interact(plot_model, feature = train.keys())\n",
    "#for index in train.keys():\n",
    "#    plot_model(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality Componenets with Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94bd7aefe6d43569bdb1e53d8d70c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='index', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nifty …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_seasons(index)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonality = {}\n",
    "frequencies = {}\n",
    "\n",
    "\n",
    "for index in train.keys():\n",
    "    seasonality[index] = fftpack.fft(train[index]['P/B'] - train[index]['P/B'].mean())\n",
    "    seasonality[index] = seasonality[index][:len(seasonality[index])//2]\n",
    "    frequencies[index] = np.argsort(-np.abs(seasonality[index]))[:5]\n",
    "    \n",
    "def plot_seasons(index):\n",
    "    Y = seasonality[index]\n",
    "    plt.plot(np.abs(Y))\n",
    "    plt.xlabel('frequency')\n",
    "    print('Max at:',np.argmax(Y))\n",
    "    print('Mean:',np.abs(Y).mean())\n",
    "    \n",
    "interact(plot_seasons, index = train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Transformer for Fourier Features\n",
    "class FourierFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, freq):\n",
    "        self.freq = freq\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        Xt = np.zeros((len(X),2*len(self.freq)))\n",
    "        for i in range(len(self.freq)):\n",
    "            Xt[:,i] = np.sin(2 * np.pi*self.freq[i]*X).reshape(-1)\n",
    "            Xt[:,2*i+1] = np.cos(2 * np.pi*self.freq[i]*X).reshape(-1)\n",
    "        return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanFeature(BaseEstimator, TransformerMixin):\n",
    "    def __int__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        m = X.mean(axis = 1)[0]\n",
    "        Xt = np.zeros(len(X))\n",
    "        Xt[:] = m\n",
    "        return Xt.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {}\n",
    "\n",
    "for index in train.keys():\n",
    "    union = FeatureUnion([('mean',MeanFeature()),('fourier',FourierFeatures(frequencies[index]))])\n",
    "    seasons[index] = Pipeline([('Index',IndexSelector()),\n",
    "                              ('union',union),\n",
    "                              ('regressor',LinearRegression())])\n",
    "    seasons[index].fit(train[index],train[index]['P/B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3432febce81426ba979931ac3e11f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nift…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model(feature)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation model with seasonality component\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "def plot_model(feature):\n",
    "    print('R2 for testing data:',seasons[feature].score(test[feature],test[feature]['P/B']))\n",
    "    predicted = seasons[feature].predict(train[feature])\n",
    "    plt.figure(figsize = (10,8))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'], label = 'Actual P/B')\n",
    "    plt.plot(train[feature]['Date'],predicted,label = 'Model P/B')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.plot(train[feature]['Date'],train[feature]['P/B'] - predicted, label ='Residual')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(test[feature]['Date'],test[feature]['P/B'], label = 'Test P/B')\n",
    "\n",
    "    plt.plot(test[feature]['Date'],seasons[feature].predict(test[feature]), label = 'Test Predictions')\n",
    "    plt.legend()\n",
    "    \n",
    "interact(plot_model, feature = train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = {}\n",
    "for index in train.keys():\n",
    "    poly_reg[index] = []\n",
    "    for i in range(1,8):\n",
    "        pipe = Pipeline([('Index',IndexSelector()),\n",
    "                ('Polynomial Features',PolynomialFeatures(degree = i)),\n",
    "                ('Regression',LinearRegression())])\n",
    "        pipe.fit(train[index],train[index]['P/B'])\n",
    "        poly_reg[index].append(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51c86c1e4b74ce09f44dd83116e8e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='index', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nifty …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate_model(index, degree)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "\n",
    "def evaluate_model(index, degree):\n",
    "    degree = degree - 1\n",
    "    r2 = poly_reg[index][degree].score(test[index],test[index]['P/B'])\n",
    "    rtrain = poly_reg[index][degree].score(train[index],train[index]['P/B'])\n",
    "    train_pred = poly_reg[index][degree].predict(train[index])\n",
    "    test_pred = poly_reg[index][degree].predict(test[index])\n",
    "    residual = train[index]['P/B'] - train_pred \n",
    "    \n",
    "    print('R2 on Test:',r2)\n",
    "    print('R2 on Train:',rtrain)\n",
    "    print('Variance:', rtrain - r2)\n",
    "    plt.figure(figsize = (10,15))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    plt.title(index + ': Polynomial Regression, Degree = ' + str(degree+1))\n",
    "    plt.plot(train[index]['Date'],train[index]['P/B'],label = 'Actual P/B Ratio')\n",
    "    plt.plot(train[index]['Date'],train_pred,label = 'Predicted P/B Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(index + ': Regression Residuals')\n",
    "    plt.plot(residual,label ='Residuals')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(index + ': Regression Performance on Test Data')\n",
    "    plt.plot(test[index]['Date'],test[index]['P/B'],label = 'P/B Ratio')\n",
    "    plt.plot(test[index]['Date'],test_pred, label = 'Test Predictions')\n",
    "    plt.legend()\n",
    "    \n",
    "    #plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + index\n",
    "    #          + '_PolynomialD' + str(degree + 1) + '.png')\n",
    "\n",
    "slider = IntSlider(min=1, max=7, step=1, description=\"Degree\")\n",
    "interact(evaluate_model, index = train.keys(), degree = slider) \n",
    "#for index in train.keys():\n",
    "#    for d in range(1,8):\n",
    "#        evaluate_model(index,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of R2 in train, R2 in test in different degrees of polynomial regression\n",
    "r2_train = []\n",
    "r2_test = []\n",
    "index_name = []\n",
    "deg = []\n",
    "for index in poly_reg.keys():\n",
    "    for i,d in enumerate(poly_reg[index]):\n",
    "        deg.append(i+1)\n",
    "        index_name.append(index)\n",
    "        r2_train.append(d.score(train[index],train[index]['P/B']))\n",
    "        r2_test.append(d.score(test[index],test[index]['P/B']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'Index':index_name,'Degree of Regression':deg,'R-Square on training data':r2_train,\n",
    "                                                        'R-Square on testing data':r2_test} \n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Degree of Regression</th>\n",
       "      <th>R-Square on training data</th>\n",
       "      <th>R-Square on testing data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>-19.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>2</td>\n",
       "      <td>0.361723</td>\n",
       "      <td>-46.610782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>3</td>\n",
       "      <td>0.655984</td>\n",
       "      <td>-1.406340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>4</td>\n",
       "      <td>0.658753</td>\n",
       "      <td>0.080568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>5</td>\n",
       "      <td>0.713320</td>\n",
       "      <td>-45.136930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549455</td>\n",
       "      <td>-0.557598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nifty Auto</td>\n",
       "      <td>7</td>\n",
       "      <td>0.525616</td>\n",
       "      <td>-0.093922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nifty Bank</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413588</td>\n",
       "      <td>-0.114996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nifty Bank</td>\n",
       "      <td>2</td>\n",
       "      <td>0.505744</td>\n",
       "      <td>-2.171626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nifty Bank</td>\n",
       "      <td>3</td>\n",
       "      <td>0.560017</td>\n",
       "      <td>-0.608056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index  Degree of Regression  R-Square on training data  \\\n",
       "0  Nifty Auto                     1                   0.212648   \n",
       "1  Nifty Auto                     2                   0.361723   \n",
       "2  Nifty Auto                     3                   0.655984   \n",
       "3  Nifty Auto                     4                   0.658753   \n",
       "4  Nifty Auto                     5                   0.713320   \n",
       "5  Nifty Auto                     6                   0.549455   \n",
       "6  Nifty Auto                     7                   0.525616   \n",
       "7  Nifty Bank                     1                   0.413588   \n",
       "8  Nifty Bank                     2                   0.505744   \n",
       "9  Nifty Bank                     3                   0.560017   \n",
       "\n",
       "   R-Square on testing data  \n",
       "0                -19.016024  \n",
       "1                -46.610782  \n",
       "2                 -1.406340  \n",
       "3                  0.080568  \n",
       "4                -45.136930  \n",
       "5                 -0.557598  \n",
       "6                 -0.093922  \n",
       "7                 -0.114996  \n",
       "8                 -2.171626  \n",
       "9                 -0.608056  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Model Variance'] = df['R-Square on training data'] - df['R-Square on testing data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'Z:\\Research\\Book Value per Share Analysis\\Project Material\\Polynomial Regression Score.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last N Day Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n):\n",
    "        self.N = n\n",
    "        self.NAvg = 0\n",
    "    def fit(self, X, y):\n",
    "        self.NAvg = y[-self.N:].mean()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(len(X))\n",
    "        pred[:] = self.NAvg\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Periods = [50,100,150,200]\n",
    "mavg = {}\n",
    "for index in train.keys():\n",
    "    mavg[index] = []\n",
    "    for period in N_Periods:\n",
    "        reg = MovingAverageRegressor(period)\n",
    "        reg.fit(X = None, y = train[index]['P/B'])\n",
    "        mavg[index].append(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac565410cca34d56b6b4047f114f598d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='index', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nifty …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.final_plot(index, period)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def final_plot(index, period):\n",
    "    period = N_Periods.index(period)\n",
    "    r2_mavg = mavg[index][period].score(test[index],test[index]['P/B'])\n",
    "    r2_reg = drift[index].score(test[index],test[index]['P/B'])\n",
    "    r2_mean = mean_drift[index].score(test[index],test[index]['P/B'])\n",
    "    train_pred = mavg[index][period].predict(train[index])\n",
    "    test_pred = mavg[index][period].predict(test[index])\n",
    "    residual = train[index]['P/B'] - train_pred\n",
    "    print('Moving Average Reg:',r2_mavg)\n",
    "    print('Linear Reg:',r2_reg)\n",
    "    print('Mean Reg:',r2_mean)\n",
    "    \n",
    "    plt.figure(figsize = (10,15))\n",
    "    period = N_Periods[period]\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.title(index + ': ' + str(period) + ' Day Average Predicting Model')\n",
    "    plt.plot(train[index]['Date'],train[index]['P/B'],label = 'Actual P/B Ratio')\n",
    "    plt.plot(train[index]['Date'],train_pred,label = 'Predicted P/B Ratio')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(index + ': ' + str(period) + ' Day Average Residuals')\n",
    "    plt.plot(residual,label ='Residuals')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(index + ': ' + str(period) + ' Day Average Performance on Test Data')\n",
    "    plt.plot(test[index]['Date'],test[index]['P/B'],label = 'Test P/B')\n",
    "    plt.plot(test[index]['Date'],test_pred, label = 'Model')\n",
    "    plt.legend()\n",
    "#    plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + index \n",
    "#              + str(period) +  'DayAvg.png')\n",
    "\n",
    "interact(final_plot, index = train.keys(), period = N_Periods)   \n",
    "#for index in train.keys():\n",
    "#    for p in N_Periods:\n",
    "#        final_plot(index,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceab932a68444281bb9ebf05e3879366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nift…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(feature)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "from ipywidgets import interact\n",
    "\n",
    "def plot(feature):\n",
    "    plt.figure(figsize = (10,6))\n",
    "    a = autocorrelation_plot(refer[feature]['P/B'])\n",
    "    plt.xlabel('Lag (Days)')\n",
    "    plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + feature \n",
    "              + '_Correl.png')\n",
    "interact(plot, feature = refer.keys())\n",
    "#for index in train.keys():\n",
    "#    plot(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 from a regressor that uses something like moving average vs R2 from mean and linear regressors. Use autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Performance Data of Linear Regression, Naive Mean Model and Last N Day Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the performance of the regressions: test\n",
    "mean_perf = []\n",
    "reg_perf = []\n",
    "avg50_perf = []\n",
    "avg100_perf = []\n",
    "avg150_perf = []\n",
    "avg200_perf = []\n",
    "for feature in test.keys():\n",
    "    mean_perf.append(mean_drift[feature].score(test[feature],test[feature]['P/B']))\n",
    "    reg_perf.append(drift[feature].score(test[feature],test[feature]['P/B']))\n",
    "    avg50_perf.append(mavg[feature][0].score(test[feature],test[feature]['P/B']))\n",
    "    avg100_perf.append(mavg[feature][1].score(test[feature],test[feature]['P/B']))\n",
    "    avg150_perf.append(mavg[feature][2].score(test[feature],test[feature]['P/B']))\n",
    "    avg200_perf.append(mavg[feature][3].score(test[feature],test[feature]['P/B']))\n",
    "\n",
    "comparison = pd.DataFrame({'Index':list(test.keys()),'Mean Regression':mean_perf,'Linear Regression':reg_perf,\n",
    "                          '50 Day MA':avg50_perf,'100 Day MA':avg100_perf,'150 Day MA':avg150_perf,\n",
    "                          '200 Day MA':avg200_perf})\n",
    "comparison.to_csv('Z:\\\\Research\\\\Book Value per Share Analysis\\\\R2TestDataComparison.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the performance of the regressions: train\n",
    "mean_perf = []\n",
    "reg_perf = []\n",
    "avg50_perf = []\n",
    "avg100_perf = []\n",
    "avg150_perf = []\n",
    "avg200_perf = []\n",
    "for feature in test.keys():\n",
    "    mean_perf.append(mean_drift[feature].score(train[feature],train[feature]['P/B']))\n",
    "    reg_perf.append(drift[feature].score(train[feature],train[feature]['P/B']))\n",
    "    avg50_perf.append(mavg[feature][0].score(train[feature],train[feature]['P/B']))\n",
    "    avg100_perf.append(mavg[feature][1].score(train[feature],train[feature]['P/B']))\n",
    "    avg150_perf.append(mavg[feature][2].score(train[feature],train[feature]['P/B']))\n",
    "    avg200_perf.append(mavg[feature][3].score(train[feature],train[feature]['P/B']))\n",
    "\n",
    "comparison = pd.DataFrame({'Index':list(test.keys()),'Mean Regression':mean_perf,'Linear Regression':reg_perf,\n",
    "                          '50 Day MA':avg50_perf,'100 Day MA':avg100_perf,'150 Day MA':avg150_perf,\n",
    "                          '200 Day MA':avg200_perf})\n",
    "comparison.to_csv('Z:\\\\Research\\\\Book Value per Share Analysis\\\\R2TrainDataComparison.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Results of ADF Test\n",
    "def station(index):\n",
    "    result = adfuller(refer[index]['P/B'])\n",
    "    \n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.title(index)\n",
    "    plt.plot(refer[index]['Date'],refer[index]['P/B'], label = 'P/B Ratio')\n",
    "    plt.plot(refer[index]['Date'],np.full(len(refer[index]['Date']),refer[index]['P/B'].mean()), label = ' Mean P/B Ratio')\n",
    "    plt.legend()\n",
    "#    plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + index \n",
    "#              + '_Stat.png')\n",
    "    \n",
    "    return result[1]\n",
    "\n",
    "p = []\n",
    "for index in refer.keys():\n",
    "    p.append(station(index))\n",
    "pd.DataFrame({'Index':list(refer.keys()),'P-Value':p}).to_csv('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Stationarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3efc6cc7ddd4a6d9ccabf899fcd92dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='index', options=('Nifty Auto', 'Nifty Bank', 'Nifty FMCG', 'Nifty …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.stat_analysis(index)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cummulative moving averae and cummulative moving variance\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "def getVariance(series):\n",
    "    l1 = np.array([series.iloc[:i].var() for i in range(len(series))])\n",
    "    l2 = np.array([series.iloc[:i].mean() for i in range(len(series))])\n",
    "    return l1,l2\n",
    "\n",
    "\n",
    "#Comparing given data to a generated stationary series with a comparable mean and variance\n",
    "def stat_analysis(index):\n",
    "    stationary_series = np.random.normal(loc = refer[index]['P/B'].mean(), scale =refer[index]['P/B'].std(), size = len(refer[index]))\n",
    "    plt.figure(figsize = (20,20))\n",
    "\n",
    "    plt.subplot(3,2,1)\n",
    "    plt.title(index)\n",
    "    plt.plot(refer[index]['Date'],refer[index]['P/B'], label = 'P/B Ratio')\n",
    "    plt.plot(refer[index]['Date'], np.full(len(refer[index]['P/B']),refer[index]['P/B'].mean()), label = 'Mean P/B Ratio')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(3,2,2)\n",
    "    plt.title('Comparative Stationary Series')\n",
    "    plt.plot(refer[index]['Date'], stationary_series, label = 'Stationary Series')\n",
    "    plt.plot(refer[index]['Date'], np.full(len(stationary_series),stationary_series.mean()), label = 'Mean')\n",
    "    plt.legend()\n",
    "\n",
    "    stat = getVariance(pd.Series(stationary_series))\n",
    "    it = getVariance(pd.Series(refer[index]['P/B']))\n",
    "\n",
    "    plt.subplot(3,2,3)\n",
    "    plt.title(index + ': Cummulative Mean')\n",
    "    plt.plot(it[1], label = 'Cummulative Mean')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3,2,4)\n",
    "    plt.title('Comparative Stationary Series: Cummulative Mean')\n",
    "    plt.plot(stat[1],label = 'Cummulative Mean')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3,2,5)\n",
    "    plt.title(index + ': Cummulative Variance')\n",
    "    plt.plot(it[0],label = 'Cummulative Variance')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3,2,6)\n",
    "    plt.title('Comparative Stationary Series: Cummulative Variance')\n",
    "    plt.plot(stat[0],label = 'Cummulative Variance')\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.savefig('Z:\\\\Research\\\\Book Value per Share Analysis\\\\Project Material\\\\Charts\\\\' + index \n",
    "    #          + '_Stat.png',bbox_inches = 'tight')\n",
    "    \n",
    "interact(stat_analysis, index = refer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving figures\n",
    "#for index in refer.keys():\n",
    "#    print(index)\n",
    "#    stat_analysis(index)\n",
    "#stat_analysis('Nifty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
